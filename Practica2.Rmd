---
title: "Practica2"
author: "Sandra Milena Patiño"
date: "3/6/2020"
output: pdf_document
---
#Práctica 2 (35% nota final)

**Presentación**

En esta práctica se elabora un caso práctico orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

**Competencias**

En esta práctica se desarrollan las siguientes competencias del Máster de Data Science:

- Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.
- Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.
Objetivos Los objetivos concretos de esta práctica son:
- Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.
- Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico.
- Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.
- Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.
- Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.
- Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.
- Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.

Siguiendo las principales etapas de un proyecto analítico, las diferentes tareas a realizar (y justificar) son las siguientes:

**1. Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?**

La Organización Mundial de la Salud ha estimado que ocurren 12 millones de muertes en todo el mundo, cada año debido a enfermedades del corazón. La mitad de las muertes en los Estados Unidos y otros países desarrollados se deben a enfermedades cardiovasculares. El pronóstico temprano de las enfermedades cardiovasculares puede ayudar a tomar decisiones sobre los cambios en el estilo de vida en pacientes de alto riesgo y, a su vez, reducir las complicaciones. Esta investigación tiene la intención de identificar los factores más relevantes de riesgo de enfermedad cardíaca, así como predecir el riesgo general mediante regresión logística

El conjunto de datos está disponible públicamente en el sitio web de Kaggle, y proviene de un estudio cardiovascular en curso en residentes de la ciudad de Framingham, Massachusetts. El objetivo de la clasificación es predecir si el paciente tiene 10 años de riesgo de enfermedad coronaria (CHD) en el futuro. El conjunto de datos proporciona la información del paciente. Incluye más de 4,000 registros y 15 atributos.

```{r setup, include=FALSE}
library(stringr)
library(ggcorrplot)
library(cowplot)
library(caret)
library(ResourceSelection)
library(pROC)
library(e1071)
library(vcd)
library(DataExplorer)
library(VIM)
library(readr)
knitr::opts_chunk$set(echo = TRUE)
```

**1. Carga de Datos**

Cargamos los datos del archivo csv descargado de www.kaggle.com

```{r}
dataset <- read.csv("datasets_framingham.csv")
head(dataset)
```

Revisamos la estructura del dataset

```{r}
str(dataset)
```

**Diccionario de datos - Descripción de los atributos**

```{r pressure, echo=FALSE, fig.cap="Tipos de Datos", out.width = '100%'}
knitr::include_graphics("tipos.png")
```

**Analisis de datos**

```{r}
summary(dataset)
```

- Hay mayor cantidad de pacientes mujeres que hombres
- Edad promedio de los pacentes 49 años
- El mayor grupo de personas no terminaron la secundaria
- La cantidad de fumadores es aprox. igual a la de no fumadores
- La mayoria de pacientes no toma medicamentos para la presion arterial, no ha tenido accidentes cerebrovasculares ni sufre de diabetes.
- En el indice de masa corporal observamos una media de 25.8 esto indica sobrepeso
- Existen una gran cantidad de valores ausentes (NA) que deben ser imputados

```{r}
colSums(is.na(dataset))
options(repr.plot.width=14, repr.plot.height=6)
plot_missing(dataset)
```

Porcentaje de datos perdidos

**Correlación**

```{r}
corr <- round(cor(dataset, use="complete.obs"), 2)
corr

ggcorrplot(corr,hc.order = TRUE, type = "lower",lab = TRUE, tl.cex = 9, lab_size = 2, sig.level = .2) + labs(fill = "Correlation")

```
Observamos alta correlación entre diatebes y glucose, currentSmoker y cigsPerDay, prevalentHyp y sys BP, sysBP y diaBP

**2. Normalización de las variables cualitativas**

Codificamos las variables categoricas cuyos valores sean (1 y 0) a valores representativos tipo char para cada variable

**2.1 Male**

```{r}
dataset$male <- ifelse( dataset$male=="0" , "F", "M" )
table(dataset$male)

```

**2.2 currentSmoker**

```{r}
dataset$currentSmoker <- ifelse( dataset$currentSmoker=="0" , "N", "S" )
table(dataset$currentSmoker)
```

**2.3 BPMeds**

```{r}
dataset$BPMeds <- ifelse( dataset$BPMeds=="0" , "N", "S" )
table(dataset$BPMeds)
```

**2.4 prevalentStroke**

```{r}
dataset$prevalentStroke <- ifelse( dataset$prevalentStroke=="0" , "N", "S" )
table(dataset$prevalentStroke)
```

**2.5 prevalentHyp**

```{r}
dataset$prevalentHyp <- ifelse( dataset$prevalentHyp=="0" , "N", "S" )
table(dataset$prevalentHyp)
```

**2.6 diabetes**

```{r}
dataset$diabetes <- ifelse( dataset$diabetes=="0" , "N", "S" )
table(dataset$diabetes)
```

**2.7 TenYearCHD**

```{r}
dataset$TenYearCHD <- ifelse( dataset$TenYearCHD=="0" , "N", "S" )
table(dataset$TenYearCHD)
```

Convertimos las variables categoricas de INT a Factor 


```{r}
dataset$male <- as.factor(dataset$male)
dataset$education <- as.factor(dataset$education)
dataset$currentSmoker <- as.factor(dataset$currentSmoker)
dataset$BPMeds <- as.factor(dataset$BPMeds)
dataset$prevalentStroke <- as.factor(dataset$prevalentStroke)
dataset$prevalentHyp <- as.factor(dataset$prevalentHyp)
dataset$diabetes <- as.factor(dataset$diabetes)
dataset$TenYearCHD <- as.factor(dataset$TenYearCHD)
str(dataset)
```

No se encuentra errores o inconsistencias en los datos


**3. Valores perdidos**

Analizar la presencia de valores perdidos. En el caso de detectar algún valor perdido en las variables cuantitativas realizar una imputación de valores en estas variables. La imputación debe hacerse con los 5 vecinos más cercanos usando la distancia de Gower, usando sólo la información de las variables cuantitativas y dentro de éstas, aquellas que tengan sentido en la imputación de la variable. Después de realizar la imputación es necesario verificar que los valores asignados se han copiado sobre el conjunto de datos originales

```{r}
#Imputación
output <- kNN( dataset, variable=c("education","cigsPerDay","BPMeds","totChol","BMI","heartRate","glucose"), k=5 )

dataset[,c("education","cigsPerDay","BPMeds","totChol","BMI","heartRate","glucose")] <- output[,c("education","cigsPerDay","BPMeds","totChol","BMI","heartRate","glucose")]

# Registros imputados
filas_imp <- dataset[ output$education_imp==TRUE | output$cigsPerDay_imp==TRUE | output$BPMeds_imp==TRUE |  output$totChol_imp==TRUE | output$BMI_imp==TRUE | output$heartRate_imp==TRUE | output$glucose_imp==TRUE, ]
head(filas_imp)
colSums(is.na(dataset))
```

**4. Graficas de Datos Categoricos**

```{r}

a = ggplot(dataset, aes(TenYearCHD, fill = TenYearCHD)) + 
  geom_bar(stat = "count") + scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "TenYearCHD") +  theme_bw(base_size = 18) +
  theme(legend.position="bottom")

b = ggplot(dataset, aes(male, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "Male", x = "") +  theme_bw(base_size = 18) +
  theme(legend.position="bottom")

options(repr.plot.width=16, repr.plot.height=8)
plot_grid(a,b, ncol = 2, nrow = 1)
```

```{r}
a = ggplot(dataset, aes(currentSmoker , fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "currentSmoker", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")

b = ggplot(dataset, aes(BPMeds, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "BPMeds", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")

plot_grid(a,b, ncol = 2, nrow = 1)
```


```{r}
a = ggplot(dataset,aes(education, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "education", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")


b = ggplot(dataset, aes(prevalentStroke, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "prevalentStroke", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")

plot_grid(a,b, ncol = 2, nrow = 1)
```


```{r}

a = ggplot(dataset, aes(prevalentHyp, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "prevalentHyp", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")

a = ggplot(dataset, aes(diabetes, fill = TenYearCHD)) + 
  geom_bar(stat = "count", position = "dodge") + 
  scale_fill_manual(values=c('grey70', 'grey20')) + 
  labs(title = "Diabetes", x = "") +  
  theme_bw(base_size = 18) + theme(legend.position="bottom")

plot_grid(a,b, ncol = 2, nrow = 1)


```

**5. Valores extremos**

Analizar la presencia de posibles valores extremos (outliers) en las variables

```{r}
boxplot(dataset$age,main="Box plot Age", col="blue")
boxplot.stats(dataset$age)$out

```



```{r}
boxplot(dataset$cigsPerDay, main="Box plot cigsPerDay", col="green")
boxplot.stats(dataset$cigsPerDay)$out

```


```{r}
boxplot(dataset$totChol,main="Box plot TotChol", col="red")
boxplot.stats(dataset$totChol)$out

```


```{r}
boxplot(dataset$sysBP,main="Box plot SysBP", col="pink")
boxplot.stats(dataset$sysBP)$out

```

```{r}
boxplot(dataset$diaBP,main="Box plot DiaBP", col="orange")
boxplot.stats(dataset$diaBP)$out

```

```{r}
boxplot(dataset$BMI,main="Box plot BMI", col="purple")
boxplot.stats(dataset$BMI)$out

```

```{r}
boxplot(dataset$heartRate,main="Box plot HeartRate", col="yellow")
boxplot.stats(dataset$heartRate)$out

```


```{r}
boxplot(dataset$glucose,main="Box plot Glucose", col="brown")
boxplot.stats(dataset$glucose)$out
```
Revisando los outliers de cada variable podemos observar que corresponden a datos validos


**6.Comprobación de la normalidad y homogeneidad de la varianza**


```{r}
a = ggplot(dataset, aes(cigsPerDay)) + geom_histogram() +
  labs(title = "Cigarettes per Day", x = "Cigarettes per Day") + 
  theme_bw(base_size = 18) 

b = ggplot(dataset, aes(totChol)) + geom_histogram(bins = 40) +
  labs(title = "Cholesterol", x = "Cholesterol") + 
  theme_bw(base_size = 18) 


plot_grid(a,b, ncol = 2, nrow = 1)
```

```{r}
a = ggplot(dataset, aes(sysBP)) + geom_histogram(bins = 40) +
  labs(title = "Systollic Blood Pressure", x = "Systollic Blood Pressure") + 
  theme_bw(base_size = 18) 

b = ggplot(dataset, aes(diaBP)) + geom_histogram(bins = 40) +
  labs(title = "Diastolic Blood Pressure", x = "Diastolic Blood Pressure") + 
  theme_bw(base_size = 18) 


plot_grid(a,b, ncol = 2, nrow = 1)
```


```{r}


a = ggplot(dataset, aes(BMI)) + geom_histogram(bins = 40) +
  labs(title = "Body Mass Index", x = "BMI") + 
  theme_bw(base_size = 18) 

b = ggplot(dataset, aes(heartRate)) + geom_histogram(bins = 40) +
  labs(title = "Heart Rate", x = "Heart Rate") + 
  theme_bw(base_size = 18) 

plot_grid(a,b, ncol = 2, nrow = 1)
```

```{r}
a = ggplot(dataset, aes(age)) + geom_histogram(bins = 40) +
  labs(title = "Age", x = "Age") + 
  theme_bw(base_size = 18) 

b = ggplot(dataset, aes(glucose)) + geom_histogram(bins = 40) +
  labs(title = "Glucose", x = "Glucose") + 
  theme_bw(base_size = 18) 

plot_grid(a,b, ncol = 2, nrow = 1)
```

**Sesgo de la distribución**


```{r}

cat("\ncigsPerDay = ", skewness(dataset$cigsPerDay)) 
cat("\ntotChol = ", skewness(dataset$totChol))
cat("\nsysBP = ", skewness(dataset$sysBP)) 
cat("\ndiaBP = ", skewness(dataset$diaBP)) 
cat("\nBMI = ", skewness(dataset$BMI)) 
cat("\nheartRate = ", skewness(dataset$heartRate)) 
cat("\nage = ", skewness(dataset$age))
cat("\nglucose = ", skewness(dataset$glucose))
```

Ligeramente sesgado hacia la derecha (>1): cigsPerDay, sysBP
Muy sesgado hacia la derecha: glucose


**QQ-Plots de la distribución**

```{r}
par(mfrow=c(1,2))
qqnorm(dataset$cigsPerDay, main = "Cigarettes per day - Normal Q-Q Plot");
qqline(dataset$cigsPerDay)
qqnorm(dataset$totChol, main = "Cholesterol - Normal Q-Q Plot");
qqline(dataset$totChol)
```

```{r}
par(mfrow=c(1,2))
qqnorm(dataset$sysBP, main = "Systollic Blood Pressure - Normal Q-Q Plot");
qqline(dataset$sysBP)
qqnorm(dataset$diaBP,  main = "Diastolic Blood Pressure - Normal Q-Q Plot");
qqline(dataset$diaBP)
```

```{r}
par(mfrow=c(1,2))
qqnorm(dataset$BMI, main = "BMI - Normal Q-Q Plot");
qqline(dataset$BMI)
qqnorm(dataset$heartRate, main = "Heart Rate - Normal Q-Q Plot");
qqline(dataset$heartRate)
```

```{r}
par(mfrow=c(1,2))
qqnorm(dataset$age, main = "Age - Normal Q-Q Plot");
qqline(dataset$age)
qqnorm(dataset$glucose, main = "Glucose - Normal Q-Q Plot");
qqline(dataset$glucose)
```

**Prueba de normalidad Shapiro Test**

Ho: Los datos estan normalmente distribuidos
H1: Los datos no estan normalmente distribuidos

```{r}
cat("\ncigsPerDay p-value =  ", as.numeric(shapiro.test(dataset$cigsPerDay)[2]))
cat("\ntotChol p-value =  ", as.numeric(shapiro.test(dataset$totChol)[2]))
cat("\nsysBP p-value =  ", as.numeric(shapiro.test(dataset$sysBP)[2]))
cat("\ndiaBP p-value =  ", as.numeric(shapiro.test(dataset$diaBP)[2]))
cat("\nBMI p-value =  ", as.numeric(shapiro.test(dataset$BMI)[2]))
cat("\nheartRate p-value =  ", as.numeric(shapiro.test(dataset$heartRate)[2]))
cat("\nage p-value =  ", as.numeric(shapiro.test(dataset$age)[2]))
cat("\nglucose p-value =  ", as.numeric(shapiro.test(dataset$glucose)[2]))
```

Como los valores de p-value son menores a alfa (0.05) se rechaza la hipotesis nula (H0) por tanto, Los datos no estan normalmente distribuidos, lo mismo podemos concluir observando las graficas QQplot 

**7. Modelo de Regresión Logística**

```{r}
logistic_model <- glm(dataset$TenYearCHD~.,family = "binomial", data = dataset)
summary(logistic_model)
varImp(logistic_model)
```

El modelo es bueno ya que la devianza residual es menor que la devianza nula

las variables de mayor signifcancia en el modelo son: age, maleM, cigsPerDay, prevalentStrokeS, sysBP, glucose

**Odds Ratio e intervalo de confianza**

```{r}
exp(logistic_model$coefficients)
exp(confint(logistic_model))
confint(logistic_model)
```

Segun los Odds ratio la probabilidad de sufrir una enfermedad coronaria en los proximos 10 años aumenta si se es hombre,si se toma medicamentos para la tensión, si el paciente había tenido previamente un accidente cerebrovascular o ha sido o es hipertenso y Si el paciente tenía diabetes  

**Bondad del ajuste**

Usa el test de Hosman-Lemeshow para ver la bondad de ajuste del modelo final

```{r}
hl <- hoslem.test(logistic_model$y, fitted(logistic_model), g=10)
hl
```

```{r}
cbind(hl$expected,hl$observed)
```

De acuerdo al p-value el cual es mayor a alfa (0.05),indica que no hay evidencia de mal ajuste. El modelo está correctamente especificado. Implica que lo que observamos se ajusta suficientemente a lo que esperado bajo el modelo.
Hay mucha proximidad entre estos valores reales y teóricos. Esto es lo que permite pensar que usar este modelo y calcular predicciones con él es suficientemente correcto

**Evaluación del modelo**

Likelihood ratio

```{r}
# Diferencia de residuos
dif_residuos <- logistic_model$null.deviance - logistic_model$deviance

# Grados libertad
df <- logistic_model$df.null - logistic_model$df.residual

# p-value
p_value <- pchisq(q = dif_residuos,df = df, lower.tail = FALSE)

paste("Diferencia de residuos:", round(dif_residuos, 4))
```

```{r}
paste("Grados de libertad:", df)
```

```{r}
paste("p-value:", p_value)
```

El modelo en conjunto sí es significativo

**Curva ROC**

```{r}
predpr <- predict(logistic_model,type=c("response"))
roccurve <- roc(dataset$TenYearCHD ~ predpr)
plot(roccurve)
auc(roccurve)
```

El área por debajo de esa curva toma el valor de 0.73, por lo que la habilidad del modelo para discriminar
es relativamente buena

**Matriz de confusión**

Para este estudio se va a emplear un threshold de 0.5

```{r}

pr1 <- ifelse(predict(logistic_model, type = "response") > 0.5, "S", "N")
t = table(predicciones = pr1, observaciones = dataset$TenYearCHD)
t
```

```{r}

cm = confusionMatrix(t, positive = "S")
cm
mosaic(t, shade = T, colorize = T,gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))

```

```{r}


cat("\nAccuracy del modelo =  ", round(cm$overall["Accuracy"],3));
cat("\nSensitivity del modelo = ", round(cm$byClass["Sensitivity"], 3));
cat("\nSpecificity del modelo = ", round(cm$byClass["Specificity"],3))


```

**tasa de error de clasificación**

```{r}
class_err = function(actual, predicted) {
  mean(actual != predicted)}

ac1 = mean(pr1 == dataset$TenYearCHD)
err1 <- class_err(actual = dataset$TenYearCHD, predicted = pr1)

cat("Accuracy del Modelo = ", ac1)
cat("\nError del Modelo = ", err1)
cat("\nAccuracy + Error = ", err1 + ac1)
```

**8.Resolución del problema. A partir de los resultados obtenidos, ¿cuáles son las conclusiones? ¿Los resultados permiten responder al problema?**

Elegimos regresión logística ya que el atributo objetivo es categóricos.

El modelo puede predecir valores correctos en un 85.6% utilizando regresión logística binomial.

La Sensibilidad del modelo es de 0.084, Tasa de Verdaderos Positivos (True Positive Rate) (TP). Es la proporción de casos positivos que fueron correctamente identificadas por el algoritmo.

La Especificidad del modelo es de 0.994, Tasa de Verdaderos Negativos, (“true negative rate” o TN). Se trata de los casos negativos que el algoritmo ha clasificado correctamente.

El modelo es bueno al predecir a las personas que no sufriran enfermedades coronarias per no es muy bueno al predecir a las personas que si las sufriran.


El código en R esta incluido en este fichero con extensión rmd y tambien se puede descargar en GitHub


**9. Archivo CSV con datos finales analizados**
```{r}
write_excel_csv2(dataset, "datasets_framingham_Processed.csv")
```
